## 全文检索：查找分词表中的数据
1. 创建的表就是


## 倒排索引：就是分词表


## Lucese： 全文检索引擎和搜索的算法代码
1. 数据如何分布，分布式存储
2. 数据如何交互
3. 数据如何备份，主从架构搭建

## es
1. 数据如何分布，数据分片
2. 平行节点，访问到哪一个节点都可以访问到数据
3. es副本机制，主数据和副本数据进行保存
4. 高级搜素功能，count,group by
5. 搜索和分析，数据分析，全文检索，结构化搜索，数据分析，海量数据实时处理，近实时的处理批处理

## es的特点
1. 可扩展性：
2. 技术整合，全文检索，数据分析，分布式i相关的数据
3. 部署简单：开箱即用
4. 接口简单：
5. 功能强大：数据库的补充

分片和副本机制：shanrd = 3： 将一份数据存储在多台节点上面，可直接存储在不同的机器上面。
副本机制：机器上面存在副本，高可用

## 数据库和elasticsearch之间的概念
1. 数据库 == index
2. rable == 索引index
3. 数据行row == 文档document
4. 数据列Column： 字段Field
5. 约束： mapping


```
手动创建索引和映射，创建索引的语法：更加符合想要实现的操作
PUT /<index_name>
{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 0
  },
  "mappings": {
    "properties": {
      "field_name": {
        "type": "<data_type>"
      },
      ...
    }
  }
}
上述代码中，PUT方法表示创建索引，<index_name>为索引名称，可以自定义命名。settings部分可以用来设置索引的一些参数，比如分片数和副本数。mappings部分定义了索引中的字段和数据类型。
具体来说，properties下定义的每个字段都需要指定一个数据类型，例如：
text：文本类型；    keyword：关键字类型，不分词；    long：长整型；     double：双精度浮点型；      date：日期类型，支持多种格式。
```

```
定制分词器

PUT /my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "type": "custom",
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "pattern",
          "pattern": "-"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "name": {
        "type": "text",
        "analyzer": "my_analyzer"
      }
    }
  }
}

该自定义分词器使用了 “pattern” 分词器来切分字符串，并将分隔符定义为 “-” 字符。上述代码中，分析器名称为 my_analyzer，它使用了自定义的分词器 my_tokenizer。同时，索引中的字段类型为 text，并通过 analyzer 属性指定了该字段所使用的分析器。
在实际应用中，可以根据具体需求，自定义更复杂和灵活的分词器，如基于正则表达式切分、结合停用词过滤等，以更好地满足业务要求。需要注意的是，在 Elasticsearch 中修改已经存在的分词器时，需要满足一定的条件，确保不会影响到索引查询性能和数据完整性

```

