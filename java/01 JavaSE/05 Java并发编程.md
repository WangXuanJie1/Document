## 线程和进程有什么区别？
线程具有许多传统进程所具有的特征，故又称为轻型进程(Light—Weight Process)或进程元；而把传统 的进程称为重型进程(Heavy—Weight Process)，它相当于只有一个线程的任务。在引入了线程的操作系
统中，通常一个进程都有若干个线程，至少包含一个线程。

根本区别：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位
资源开销：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线 程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计
数器（PC），线程之间切换的开销小。
包含关系：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的； 线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。
内存分配：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的
影响关系：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死 掉。所以多进程要比多线程健壮。
执行过程：每个独立的进程有程序运行的入口. 顺序执行序列和程序出口。但是线程不能独立执行，必 须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行

## 创建线程的三种方式的对比
线程类只是实现了Runnable接口或Callable接口，还可以继承其他类。
使用继承Thread类的方式创建多线程

## Runnable和Callable的区别
1. Callable规定（重写）的方法是call()，Runnable规定（重写）的方法是run()。
2. Callable的任务执行后可返回值，而Runnable的任务是不能返回值的。
3. Call方法可以抛出异常，run方法不可以。
4. 运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的 方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。

## 为什么要使用多线程呢
1. 从计算机底层来说： 线程可以比作是轻量级的进程，是程序执行的最小单位,线程间的切换和调度 的成本远远小于进程。另外，多核 CPU 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。
2. 单核时代： 在单核时代多线程主要是为了提高 CPU 和 IO 设备的综合利用率。举个例子：当只 有一个线程的时候会导致 CPU 计算时，IO 设备空闲；进行 IO 操作时，CPU 空闲。我们可以简单 地说这两者的利用率目前都是 50%左右。但是当有两个线程的时候就不一样了，当一个线程执行 CPU 计算时，另外一个线程可以进行 IO 操作，这样两个的利用率就可以在理想情况下达到 100%了。
3. 多核时代:多核时代多线程主要是为了提高 CPU 利用率。举个例子：假如我们要计算一个复杂的 任务，我们只用一个线程的话，CPU 只会一个 CPU 核心被利用到，而创建多个线程就可以让多个
CPU 核心被利用到，这样就提高了 CPU 的利用率。

## 线程的状态流转
1. 新建状态（New） ：当线程对象对创建后，即进入了新建状态，如：Thread t = new MyThread();
2. 绪状态（Runnable） ：当调用线程对象的start()方法（t.start();），线程即进入就绪状态。处于 就绪状态的线程，只是说明此线程已经做好了准备，随时等待CPU调度执行，并不是说执行了t.start()此线程立即就会执行；
3. 运行状态（Running） ：当CPU开始调度处于就绪状态的线程时，此时线程才得以真正执行，即进 入到运行状态。注：就 绪状态是进入到运行状态的唯一入口，也就是说，线程要想进入运行状态执行，首先必须处于就绪状态中；
4. 阻塞状态（Blocked） ：处于运行状态中的线程由于某种原因，暂时放弃对CPU的使用权，停止执 行，此时进入阻塞状态，直到其进入到就绪状态，才 有机会再次被CPU调用以进入到运行状态。根据阻塞产生的原因不同，阻塞状态又可以分为三种：
 
 等待阻塞：运行状态中的线程执行wait()方法，使本线程进入到等待阻塞状态；
 同步阻塞 — 线程在获取synchronized同步锁失败(因为锁被其它线程所占用)，它会进入同步阻塞状 态；
 其他阻塞 — 通过调用线程的sleep()或join()或发出了I/O请求时，线程会进入到阻塞状态。当sleep()状 态超时. join()等待线程终止或者超时. 或者I/O处理完毕时，线程重新转入就绪状态。

## 什么是线程死锁?如何避免死锁?
1. 多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻 塞，因此程序不可能正常终止。
2. 互斥条件：该资源任意一个时刻只由一个线程占用。
3. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
4. 不剥夺条件:线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释 放资源。
5. 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

## 如何避免线程死锁?
1. 破坏互斥条件 这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）
2. 破坏请求与保持条件 一次性申请所有的资源。
3. 破坏不剥夺条件 占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
4. 破坏循环等待条件 靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。
5. 锁排序法：（必须回答出来的点） 指定获取锁的顺序，比如某个线程只有获得A锁和B锁，才能对某资源进行操作，只有获得A锁的线程才有资格获取B锁，按顺序获取锁就可以避

 ## sleep() 方法和 wait() 方法区别和共同点?
 1. sleep方法：是Thread类的静态方法，当前线程将睡眠n毫秒，线程进入阻塞状态。当睡眠时间到 了，会解除阻塞，进入可运行状态，等待CPU的到来。睡眠不释放锁（如果有的话）。
 2. wait方法：是Object的方法，必须与synchronized关键字一起使用，线程进入阻塞状态，当notify 或者notifyall被调用后，会解除阻塞。但是，只有重新占用互斥锁之后才会进入可运行状态。睡眠 时，会释放互斥锁。sleep 方法没有释放锁，
 3. sleep 方法没有释放锁，而 wait 方法释放了锁 。
 4. sleep 通常被用于暂停执行Wait 通常被用于线程间交互/通信
 5. sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout)超时后线程会自动苏 醒。
 6. wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者notifyAll() 方法


## 为什么我们调用 start() 方法时会执行 run() 方法， 为什么我们不 能直接调用 run() 方法
1. new 一个 Thread，线程进入了新建状态; 调用start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，（调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。）这是真正的多线程工作。
2. 直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程 中执行它，所以这并不是多线程工作。
3. 调用 start 方法方可启动线程并使线程进入就绪状态， 而 run 方法只是 thread 的一个普通 方法调用， 还是在主线程里执行。

## Thread类中的yield方法有什么作用？
Yield方法可以暂停当前正在执行的线程对象，让其它有相同优先级的线程执行。它是一个静态方法 而且只保证当前线程放弃CPU占用而不能保证使其它线程一定能占用CPU，执行yield()的线程有可能在
进入到暂停状态后马上又被执行。

## 谈谈volatile的使用及其原理
1. volatile保证变量对所有线程的可见性：当volatile变量被修改，新值对所有线程会立即更新。或者 理解为多线程环境下使用volatile修饰的变量的值一定是最新的。
2. jdk1.5以后volatile完全避免了指令重排优化，实现了有序性。有序性：Java 程序的指令重排优化是为了提升程序执行速度，但是在多线程环境下指令重排可能会导致程序的结果与预期不符。volatile 关键字可以防止指令重排，保证程序执行顺序按照代码规定的顺序进行，从而避免了由于指令重排导致的线程安全问题。
3. 虽然 volatile 关键字可以保证变量的可见性和有序性，但并不能保证原子性，即不能保证多个线程对同一变量的并发访问是安全的。如果需要保证多个线程对同一变量的操作是原子性的，还需要使用 synchronized 或者 atomic 类等线程安全工具来实现。
指令重排：

1. 指令重排的本质在于程序在执行时，CPU 并不一定按照程序中编写的顺序来执行指令，而是根据 CPU 的实现和执行情况来动态地调整指令执行顺序，以尽量提高程序的执行效率。这种指令重排通常只会影响程序的执行速度而不会对程序的输出结果产生影响。
2. 指令重排有助于提高程序的运行效率，但同时也带来了风险。如果在多线程环境下存在共享变量的情况，由于指令重排可能导致代码执行顺序发生变化，从而引发线程安全问题。
3. 为了保证多线程程序的正确性，Java 提供了一些手段来禁止指令重排。例如，使用 synchronized、volatile 和 final 等关键字可以明确地告诉编译器或处理器不要重排某些指令，从而避免了因指令重排导致的线程安全问题。

## CAS了解吗？
CAS：全称 Compare and swap，即比较并交换，它是一条 CPU 同步原语。是一种硬件对并发 的支持，针对多处理器操作而设计的一种特殊指令，用于管理对共享数据的并发访问。
####  ABA 问题
并发环境下，假设初始条件是A，去修改数据时，发现是A就会执行修改。但是看到的虽然是A，中间可 能发生了A变B，B又变回A的情况。此时A已经非彼A，数据即使成功修改，也可能有问题。
可以通过AtomicStampedReference解决ABA问题，它，一个带有标记的原子引用类，通过控制变量值 的版本来保证CAS的正确性。

#### 循环时间长开销
自旋CAS，如果一直循环执行，一直不成功，会给CPU带来非常大的执行开销。 很多时候，CAS思想体现，是有个自旋次数的，就是为了避开这个耗时问题~

#### 只能保证一个变量的原子操作
CAS 保证的是对一个变量执行操作的原子性，如果对多个变量操作时，CAS 目前无法直接保证操作的原子性的。
使用互斥锁来保证原子性；将多个变量封装成对象，通过AtomicReference来保证原子性。

## 互斥锁和悲观锁  synchronized
互斥锁（Mutex Lock）是一种传统的同步机制，它主要用于在多线程环境下对共享资源的互斥访问。在使用互斥锁时，同一时刻只允许一个线程持有该锁，其他线程需要等待该锁被释放才能进行访问。互斥锁适用于对临界区进行加锁，防止出现数据竞争和并发修改等问题，可以有效保证程序的正确性和可靠性。
悲观锁（Pessimistic Lock）则是一种基于数据库事务的锁机制，在操作数据时默认其他事务会对数据进行修改，因此需要先将数据进行加锁以保证当前事务能够安全地进行数据修改操作。悲观锁适用于并发量较大，数据冲突概率较高的场景下使用，可以有效减少数据修改时出现冲突和错误的概率。

1. 实现方式：互斥锁通常是通过操作系统提供的进程或线程间通信（IPC）机制实现，而悲观锁通常是通过数据库的事务机制实现。
2. 应用场景：互斥锁适用于在多线程环境下对共享资源的互斥访问，而悲观锁适用于对数据进行修改时可能出现的并发冲突和数据竞争等问题
3. 加锁方式：互斥锁通常需要程序员显式地获取和释放锁，而悲观锁通常由数据库事务自动处理，程序员无需手动加锁。

## synchronized 和 volatile 的区别是什么？
volatile 解决的是内存可见性问题，会使得所有对 volatile 变量的读写都直接写入主存，即 保证 了变量的可见性。
synchronized 解决的事执行控制的问题，它会阻止其他线程获取当前对象的监控锁，这样一来就让当 前对象中被 synchronized 关键字保护的代码块无法被其他线程访问，也就是无法并发执行。而且，
synchronized 还会创建一个 内存屏障，内存屏障指令保证了所有 CPU 操作结果都会直接刷到主存 中，从而 保证操作的内存可见性，同时也使得这个锁的线程的所有操作都 happens-before 于随后获得这个锁的线程的操作。

1. volatile 本质是在告诉 JVM 当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读 取； synchronized 则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。
2. volatile 仅能使用在变量级别；synchronized 则可以使用在 变量. 方法. 和类级别的
3. volatile 仅能实现变量的修改可见性，不能保证原子性；而synchronized 则可以 保证变量的修 改可见性和原子性
4. volatile 不会造成线程的阻塞；synchronized 可能会造成线程的阻塞。
5. volatile 标记的变量不会被编译器优化；synchronized 标记的变量可以被编译器优化。

## synchronized 和 Lock 有什么区别？
1. synchronized 可以给类. 方法. 代码块加锁；而 lock 只能给代码块加锁。
2. synchronized 不需要手动获取锁和释放锁，使用简单，发生异常会自动释放锁，不会造成死锁； 而 lock 需要自己加锁和释放锁，如果使用不当没有 unLock()去释放锁就会造成死锁。
3. 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。

## synchronized 和 ReentrantLock 区别是什么？
#### 两者都是可重入锁
可重入锁：重入锁，也叫做递归锁，可重入锁指的是在一个线程中可以多次获取同一把锁，比如： 一个线程在执行一个带锁的方法，该方法中又调用了另一个需要相同锁的方法，则该线程可以直接执行 调用的方法，而无需重新获得锁，
两者都是同一个线程每进入一次，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。

#### synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API
synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关 键字进行了很多优化，但是这些优化都是在虚拟机层面实现的 
ReentrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally
语句块来完成）

#### ReentrantLock 比 synchronized 增加了一些高级功能
1. 等待可中断.通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃 等待，改为处理其他事情。
2. ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁 就是先等待的线程先获得锁。 ReentrantLock默认情况是非公平的，可以通过 ReentrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。
3. ReentrantLock类线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在 调度线程上更加灵活。 在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择
的，用ReentrantLock类结合Condition实例可以实现“选择性通知”

## Synchronized的作用有哪些？
1. 原子性：确保线程互斥的访问同步代码；
2. 可见性：保证共享变量的修改能够及时可见，其实是通过Java内存模型中的 “对一个变量unlock 操作之前， 必须要同步到主内存中； 如果对一个变量进行lock操作， 则将会清空工作内存中 此变量的值， 在执行引擎使用此变量前， 需要重新从主内存中load操作或assign操作初始化变量值” 来保证的；
3. 有序性：有效解决重排序问题，即 “一个unlock操作先行发生(happen-before)于后面对同一个锁的 lock操作”。

## 说一下 synchronized 底层实现原理？
synchronized 同步代码块的实现是通过 monitorenter 和 monitorexit 指令
monitorenter 指令 指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。当

执行 monitorenter 指 令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中， synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权。
其内部包含一个计数器，当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在 执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止
synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，

得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。

## 多线程中 synchronized 锁升级的原理是什么？
synchronized 锁升级原理：在锁对象的对象头里面有一个 threadid 字段，在第一次访问的时候 threadid 为空，
jvm 让其持有偏向锁，并将 threadid 设置为其线程 id，再次进入的时候会先判断 threadid 是否与其线程 id 一致，如果一致则可以直接使用此对象，
如果不一致，则升级偏向锁为轻量级锁，通过自旋循环一定次数来获取锁，
执行一定次数之后，如果还没有正常获取到要使用的对象，此时 就会把锁从轻量级升级为重量级锁，此过程就构成了 synchronized 锁的升级。
锁的升级的目的：锁升级是为了减低了锁带来的性能消耗。在 Java 6 之后优化 synchronized 的实现方式，使用了偏向锁升级为轻量级锁再升级到重量级锁的方式，从而减低了锁带来的性能消耗。

## synchronized 为什么是非公平锁？ 非公平体现在哪些地方





   




